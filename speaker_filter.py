# /workspace/new_speaker_filter.py (è©±è€…IDè­˜åˆ¥å¯¾å¿œç‰ˆ)
import torch
import torchaudio
from speechbrain.inference.classifiers import EncoderClassifier
import os
import logging

logger = logging.getLogger(__name__)

def load_audio(path: str, target_sample_rate=16000):
    if not os.path.exists(path):
        raise FileNotFoundError(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")

    signal, fs = torchaudio.load(path)
    if signal.shape[0] > 1:
        signal = signal.mean(dim=0, keepdim=True)
    if fs != target_sample_rate:
        resampler = torchaudio.transforms.Resample(orig_freq=fs, new_freq=target_sample_rate)
        signal = resampler(signal)
    return signal

class SpeakerGuard:
    def __init__(self):
        print("â³ [SpeakerGuard] ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... (SpeechBrain)")
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.classifier = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb",
            savedir="pretrained_models/spkrec-ecapa-voxceleb",
            run_opts={"device": self.device}
        )
        # æ§‹é€ å¤‰æ›´: ãƒªã‚¹ãƒˆã§ã¯ãªãã€è¾æ›¸ã®ãƒªã‚¹ãƒˆ [{'id': 'User 0', 'emb': tensor}, ...]
        self.known_speakers = [] 
        self.threshold = 0.35 
        print(f"âœ… [SpeakerGuard] æº–å‚™å®Œäº† (Device: {self.device})")

    def extract_embedding(self, audio_tensor):
        audio_tensor = audio_tensor.to(self.device)
        if audio_tensor.ndim == 1:
            audio_tensor = audio_tensor.unsqueeze(0)
        wav_lens = torch.ones(audio_tensor.shape[0]).to(self.device)
        with torch.no_grad():
            embedding = self.classifier.encode_batch(audio_tensor, wav_lens)
        return embedding

    def identify_speaker(self, audio_tensor) -> tuple[bool, str]:
        """
        Tensorã‚’å—ã‘å–ã‚Šã€(ç™»éŒ²æ¸ˆã¿ã‹, è©±è€…ID) ã‚’è¿”ã™
        """
        try:
            current_embedding = self.extract_embedding(audio_tensor)
            
            # åˆå›ç™»éŒ² (ã‚ªãƒ¼ãƒŠãƒ¼)
            if not self.known_speakers:
                print("ğŸ”’ [SpeakerGuard] æœ€åˆã®è©±è€…ã‚’ 'User 0' (ã‚ªãƒ¼ãƒŠãƒ¼) ã¨ã—ã¦ç™»éŒ²")
                self.known_speakers.append({'id': 'User 0', 'emb': current_embedding})
                return True, "User 0"

            max_score = -1.0
            best_match_id = "Unknown"
            is_match = False

            # å…¨ç™»éŒ²è€…ã¨æ¯”è¼ƒã—ã¦ã€æœ€ã‚‚ä¼¼ã¦ã„ã‚‹äººã‚’æ¢ã™
            for speaker in self.known_speakers:
                score = torch.nn.functional.cosine_similarity(
                    speaker['emb'], current_embedding, dim=-1
                )
                score_val = score.item()
                
                if score_val > max_score:
                    max_score = score_val
                    if score_val > self.threshold:
                        is_match = True
                        best_match_id = speaker['id']

            if is_match:
                logger.info(f"âœ… [SpeakerGuard] èªè¨¼æˆåŠŸ: {best_match_id} (ã‚¹ã‚³ã‚¢: {max_score:.4f})")
                return True, best_match_id
            else:
                logger.info(f"ğŸš« [SpeakerGuard] æœªçŸ¥ã®è©±è€… (æœ€å¤§ã‚¹ã‚³ã‚¢: {max_score:.4f})")
                return False, "Unknown"
                
        except Exception as e:
            print(f"[SpeakerGuard Error] è­˜åˆ¥å¤±æ•—: {e}")
            return False, "Error"

    def register_new_speaker(self, audio_path: str) -> str:
        """
        æ–°è¦ç™»éŒ²ã—ã€å‰²ã‚Šå½“ã¦ãŸIDã‚’è¿”ã™
        """
        try:
            audio_tensor = load_audio(audio_path)
            new_emb = self.extract_embedding(audio_tensor)
            
            # æ–°ã—ã„IDã‚’ç”Ÿæˆ (User 1, User 2...)
            new_id = f"User {len(self.known_speakers)}"
            
            self.known_speakers.append({'id': new_id, 'emb': new_emb})
            print(f"ğŸ“ [SpeakerGuard] æ–°è¦ç™»éŒ²å®Œäº†: {new_id}")
            return new_id
        except Exception as e:
            print(f"[SpeakerGuard Error] ç™»éŒ²å¤±æ•—: {e}")
            return None

    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼ˆä»Šå›ã¯ä½¿ã‚ãªã„ï¼‰
    def verify_tensor(self, audio_tensor):
        is_ok, _ = self.identify_speaker(audio_tensor)
        return is_ok