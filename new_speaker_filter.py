# /workspace/speaker_filter.py
import torch
import torchaudio
from speechbrain.inference.classifiers import EncoderClassifier
import os

# --- 1. éŸ³å£°èª­ã¿è¾¼ã¿é–¢æ•° ---
def load_audio(path: str, target_sample_rate=16000):
    if not os.path.exists(path):
        raise FileNotFoundError(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")

    signal, fs = torchaudio.load(path)

    # ã‚¹ãƒ†ãƒ¬ã‚ªâ†’ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    if signal.shape[0] > 1:
        signal = signal.mean(dim=0, keepdim=True)

    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (16kHzå¿…é ˆ)
    if fs != target_sample_rate:
        resampler = torchaudio.transforms.Resample(orig_freq=fs, new_freq=target_sample_rate)
        signal = resampler(signal)

    return signal

# --- 2. å£°ç´‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹ ---
class SpeakerGuard:
    def __init__(self):
        print("â³ [SpeakerGuard] ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... (åˆå›ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™)")
        self.classifier = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb",
            savedir="pretrained_models/spkrec-ecapa-voxceleb",
            run_opts={"device": "cuda" if torch.cuda.is_available() else "cpu"}
        )
        
        # â˜…å¤‰æ›´ç‚¹: 1äººã ã‘ã§ãªãã€è¤‡æ•°ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆã«ã™ã‚‹
        self.allowed_embeddings = [] 
        
        # é–¾å€¤ (ã”æç¤ºã®é€šã‚Š0.35ã§è¨­å®šã€‚å³ã—ã„å ´åˆã¯0.25ã¸)
        self.threshold = 0.35 
        print("âœ… [SpeakerGuard] æº–å‚™å®Œäº†")

    def extract_embedding(self, audio_tensor):
        with torch.no_grad():
            embedding = self.classifier.encode_batch(audio_tensor)
        return embedding

    def register_new_speaker(self, audio_path: str) -> bool:
        """
        â˜…è¿½åŠ æ©Ÿèƒ½: æŒ‡å®šã•ã‚ŒãŸéŸ³å£°ã‚’æ–°ã—ã„è©±è€…ã¨ã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹
        """
        try:
            audio_tensor = load_audio(audio_path)
            new_emb = self.extract_embedding(audio_tensor)
            self.allowed_embeddings.append(new_emb)
            print(f"ğŸ“ [SpeakerGuard] æ–°ã—ã„è©±è€…ã‚’ç™»éŒ²ã—ã¾ã—ãŸ (ç¾åœ¨ {len(self.allowed_embeddings)} äºº)")
            return True
        except Exception as e:
            print(f"[SpeakerGuard Error] ç™»éŒ²å¤±æ•—: {e}")
            return False

    def is_owner(self, audio_path: str) -> bool:
        """
        å…¥åŠ›éŸ³å£°ãŒç™»éŒ²æ¸ˆã¿ãƒªã‚¹ãƒˆã®èª°ã‹ã¨ä¸€è‡´ã™ã‚‹ã‹åˆ¤å®š
        """
        try:
            audio_tensor = load_audio(audio_path)
        except Exception as e:
            print(f"[SpeakerGuard Error] èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return False

        current_embedding = self.extract_embedding(audio_tensor)

        # â˜…å¤‰æ›´ç‚¹: ã¾ã èª°ã‚‚ç™»éŒ²ã•ã‚Œã¦ã„ãªã‘ã‚Œã°ã€æœ€åˆã®1äººã‚’è‡ªå‹•ç™»éŒ²
        if not self.allowed_embeddings:
            print("ğŸ”’ [SpeakerGuard] æœ€åˆã®è©±è€…ã‚’ã‚ªãƒ¼ãƒŠãƒ¼ã¨ã—ã¦è‡ªå‹•ç™»éŒ²ã—ã¾ã—ãŸ")
            self.allowed_embeddings.append(current_embedding)
            return True

        # â˜…å¤‰æ›´ç‚¹: ãƒªã‚¹ãƒˆå†…ã®å…¨å“¡ã¨æ¯”è¼ƒã—ã€ä¸€äººã§ã‚‚é–¾å€¤ã‚’è¶…ãˆã‚Œã°OK
        max_score = -1.0
        is_match = False

        for saved_emb in self.allowed_embeddings:
            score = torch.nn.functional.cosine_similarity(
                saved_emb, current_embedding, dim=-1
            )
            score_val = score.item()
            
            if score_val > max_score:
                max_score = score_val
            
            if score_val > self.threshold:
                is_match = True
                break # ä¸€äººã§ã‚‚ä¸€è‡´ã™ã‚Œã°ãƒ«ãƒ¼ãƒ—çµ‚äº†

        if is_match:
            print(f"âœ… [SpeakerGuard] æœ¬äººç¢ºèªOK (ã‚¹ã‚³ã‚¢: {max_score:.4f})")
        else:
            print(f"ğŸš« [SpeakerGuard] ãƒ–ãƒ­ãƒƒã‚¯ (æœ€å¤§ã‚¹ã‚³ã‚¢: {max_score:.4f})")
            
        return is_match