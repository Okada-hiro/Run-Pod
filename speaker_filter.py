# /workspace/speaker_filter.py
import torch
import torchaudio
from speechbrain.inference.speakers import EncoderClassifier
import os

# --- 1. éŸ³å£°èª­ã¿è¾¼ã¿é–¢æ•° ---
def load_audio(path: str, target_sample_rate=16000):
    if not os.path.exists(path):
        raise FileNotFoundError(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")

    signal, fs = torchaudio.load(path)

    # ã‚¹ãƒ†ãƒ¬ã‚ªâ†’ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    if signal.shape[0] > 1:
        signal = signal.mean(dim=0, keepdim=True)

    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (16kHzå¿…é ˆ)
    if fs != target_sample_rate:
        resampler = torchaudio.transforms.Resample(orig_freq=fs, new_freq=target_sample_rate)
        signal = resampler(signal)

    return signal

# --- 2. å£°ç´‹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹ ---
class SpeakerGuard:
    def __init__(self):
        print("â³ [SpeakerGuard] ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­... (åˆå›ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™)")
        # ECAPA-TDNN ã¨ã„ã†éå¸¸ã«ç²¾åº¦ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        self.classifier = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-ecapa-voxceleb",
            savedir="pretrained_models/spkrec-ecapa-voxceleb",
            run_opts={"device": "cuda" if torch.cuda.is_available() else "cpu"} # GPUãŒã‚ã‚Œã°ä½¿ã†
        )
        self.owner_embedding = None
        # é¡ä¼¼åº¦ã®é–¾å€¤ (0.0ã€œ1.0)ã€‚0.25ã€œ0.35ã‚ãŸã‚ŠãŒä¸€èˆ¬çš„
        # å€¤ã‚’å°ã•ãã™ã‚‹ã¨å³ã—ããªã‚Šã€å¤§ããã™ã‚‹ã¨ç·©ããªã‚‹
        self.threshold = 0.35 
        print("âœ… [SpeakerGuard] æº–å‚™å®Œäº†")

    def extract_embedding(self, audio_tensor):
        """
        éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€Œå£°ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã€ã‚’æŠ½å‡ºã™ã‚‹
        """
        with torch.no_grad():
            # æ¨è«–å®Ÿè¡Œ
            embedding = self.classifier.encode_batch(audio_tensor)
        return embedding

    def is_owner(self, audio_path: str) -> bool:
        """
        å…¥åŠ›ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ªãƒ¼ãƒŠãƒ¼ã‹åˆ¤å®šã™ã‚‹
        """
        # éŸ³å£°ã‚’ãƒ­ãƒ¼ãƒ‰
        try:
            audio_tensor = load_audio(audio_path)
        except Exception as e:
            print(f"[SpeakerGuard Error] èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return False

        # ç¾åœ¨ã®å£°ã®ç‰¹å¾´ã‚’å–å¾—
        current_embedding = self.extract_embedding(audio_tensor)

        # ã¾ã ã‚ªãƒ¼ãƒŠãƒ¼ãŒã„ãªã‘ã‚Œã°ã€ã“ã®äººã‚’ã‚ªãƒ¼ãƒŠãƒ¼ã«ã™ã‚‹
        if self.owner_embedding is None:
            print("ğŸ”’ [SpeakerGuard] æœ€åˆã®è©±è€…ã‚’ã‚ªãƒ¼ãƒŠãƒ¼ã¨ã—ã¦ç™»éŒ²ã—ã¾ã—ãŸ")
            self.owner_embedding = current_embedding
            return True

        # é¡ä¼¼åº¦åˆ¤å®š (ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦)
        # score ã¯ -1.0(åˆ¥äºº) ã€œ 1.0(æœ¬äºº) ã®ç¯„å›²
        score = torch.nn.functional.cosine_similarity(
            self.owner_embedding, current_embedding, dim=-1
        )
        
        # ã‚¹ã‚³ã‚¢ã‚’å–ã‚Šå‡ºã™
        score_val = score.item()
        
        # ã“ã“ã§ã¯ã€Œé–¾å€¤ã‚ˆã‚Šã‚¹ã‚³ã‚¢ãŒé«˜ã‘ã‚Œã°æœ¬äººã€ã¨åˆ¤å®š
        is_match = score_val > self.threshold
        
        if is_match:
            print(f"âœ… [SpeakerGuard] æœ¬äººç¢ºèªOK (ã‚¹ã‚³ã‚¢: {score_val:.4f})")
        else:
            print(f"ğŸš« [SpeakerGuard] ä»–äººã®å£°ã‚’ãƒ–ãƒ­ãƒƒã‚¯ (ã‚¹ã‚³ã‚¢: {score_val:.4f})")
            
        return is_match